{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject_ocr",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkuAFqAeC6ISXFmian3aWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edebolt85/PythonFinalProject/blob/main/Final%20Project%20OCR%20Notebook\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDjEr57jPwQU"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "import pytesseract\n",
        "import PIL\n",
        "import pandas\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import regex as re\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Create a new directory and set it as the place to look for images we want to analyze\n",
        "#!mkdir /images\n",
        "image_dir = \"/images\"\n",
        "\n",
        "#Create a list of all the image paths that are found in our image directory\n",
        "images = glob.glob(image_dir + '/*.*')\n",
        "\n",
        "#This function will use Regex to search for specific criteria and mask the text if found\n",
        "def searchText(data,x,y,w,h):\n",
        "  \n",
        "  #Search for phone numbers\n",
        "  if re.search(r\"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\", data):\n",
        "    cv2.rectangle(image,(x,y),(x+w,y+h),(128,128,128),-1)\n",
        "    cv2.putText(image, \"Phone Number Hidden\", (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,204), 2)\n",
        "\n",
        "  #Search for email addresses\n",
        "  if re.search(r\"^(\\w|\\.|\\_|\\-)+[@](\\w|\\_|\\-|\\.)+[.]\\w{2,3}\", data):\n",
        "    cv2.rectangle(image,(x,y),(x+w,y+h),(128,128,128),-1)\n",
        "    cv2.putText(image, \"Email Address Hidden\", (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,204), 2)\n",
        "\n",
        "\n",
        "#Loop through all the individual images and perform multiple functions\n",
        "for file in images:\n",
        "\n",
        "  #For every image we are going to store 3 copies so that each copy can be recalled for a specific use.\n",
        "  #The 'image' copy will be the primary version that we will be working with\n",
        "  original = cv2.imread(file)\n",
        "  image = cv2.imread(file)\n",
        "  image2 = cv2.imread(file)\n",
        "\n",
        "  #Convert the 'image' file to grayscale, for improved processing\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  #Apply thresholding to the image in order to highlight pixels that meet criteria\n",
        "  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  #Process the image to accentuate features/objects and to find the contours/edges of the features\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "  inverted_thresh = 255 - thresh\n",
        "  dilate = cv2.dilate(inverted_thresh, kernel, iterations=4)\n",
        "  cnts = cv2.findContours(dilate, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  \n",
        "  #Use PyTesseract's 'image to data' function to extract the text found and store it in a dataframe\n",
        "  text = pytesseract.image_to_data(image, output_type='data.frame')\n",
        " \n",
        "  #Remove any objects where the confidence is -1\n",
        "  text = text[text.conf != -1]\n",
        "\n",
        "  #Group features (i.e. text) that have the same block number (located near each other)\n",
        "  lines = text.groupby('block_num')['text'].apply(list)\n",
        "  conf = text.groupby(['block_num'])['conf'].mean()\n",
        "  \n",
        "  #Set the contours from the output of the findContours function\n",
        "  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "\n",
        "  #Loop through contour coordinates\n",
        "\n",
        "  for c in cnts:\n",
        "    x,y, w, h = cv2.boundingRect(c)\n",
        "\n",
        "    #Filter selection of image based on contour coordinates\n",
        "    ROI = thresh[y:y + h, x:x + w]\n",
        "\n",
        "    #Extract text from selected area of image\n",
        "    data = pytesseract.image_to_string(ROI, lang='eng', config='--psm 6').lower()\n",
        "    \n",
        "    #Place a rectangle around the coordinates and save the output as 'image2'\n",
        "    cv2.rectangle(image2, (x, y), (x + w, y + h), (0, 255, 0), 0)\n",
        "\n",
        "    #Call the searchText function to determine if the current data value contains information we wish to hide\n",
        "    searchText(data,x,y,w,h)\n",
        "\n",
        "\n",
        "    #For each image analyzed create a 3 image output\n",
        "    #Original image, image with text identified, and then the image with data masked\n",
        "  list_img = [original, image2, image]\n",
        "  imgs_comb = np.hstack(list_img)\n",
        "  cv2_imshow(imgs_comb)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}